{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarthikeyanBaskaran/voice_to_form/blob/main/Healthcare_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "y1fiC28tVH4k"
      },
      "id": "y1fiC28tVH4k",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original = pd.read_csv('https://raw.githubusercontent.com/KarthikeyanBaskaran/voice_to_form/refs/heads/main/Dataset/Healthcare%20Merged%20Dataset.csv')"
      ],
      "metadata": {
        "id": "93yUMkcEVNvt"
      },
      "id": "93yUMkcEVNvt",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original = original.drop('Unnamed: 3', axis=1)\n",
        "original.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eEP7uL40VZa7",
        "outputId": "2b630889-6c6d-498d-d639-6cbfa5c27bfb"
      },
      "id": "eEP7uL40VZa7",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID                      Patient Information  \\\n",
              "0   1   Name: Robert M., Age: 42, Gender: Male   \n",
              "1   2  Name: Sarah T., Age: 25, Gender: Female   \n",
              "2   3     Name: John D., Age: 50, Gender: Male   \n",
              "3   4  Name: Emily S., Age: 28, Gender: Female   \n",
              "4   5  Name: Michael B., Age: 34, Gender: Male   \n",
              "\n",
              "                                  Symptoms & History  \n",
              "0  Doctor, I’ve been feeling dizzy whenever I exe...  \n",
              "1  My face keeps breaking out, especially around ...  \n",
              "2  I’ve been feeling weak and fatigued throughout...  \n",
              "3  There’s a painful knot in my shoulder blade th...  \n",
              "4  When I wake up in the morning, my body feels e...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef33e54e-9191-408d-9681-0f94506daa2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Patient Information</th>\n",
              "      <th>Symptoms &amp; History</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Name: Robert M., Age: 42, Gender: Male</td>\n",
              "      <td>Doctor, I’ve been feeling dizzy whenever I exe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Name: Sarah T., Age: 25, Gender: Female</td>\n",
              "      <td>My face keeps breaking out, especially around ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Name: John D., Age: 50, Gender: Male</td>\n",
              "      <td>I’ve been feeling weak and fatigued throughout...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Name: Emily S., Age: 28, Gender: Female</td>\n",
              "      <td>There’s a painful knot in my shoulder blade th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Name: Michael B., Age: 34, Gender: Male</td>\n",
              "      <td>When I wake up in the morning, my body feels e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef33e54e-9191-408d-9681-0f94506daa2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef33e54e-9191-408d-9681-0f94506daa2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef33e54e-9191-408d-9681-0f94506daa2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a96e6e5b-41ef-41b6-ac60-ee7167385d71\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a96e6e5b-41ef-41b6-ac60-ee7167385d71')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a96e6e5b-41ef-41b6-ac60-ee7167385d71 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "original",
              "summary": "{\n  \"name\": \"original\",\n  \"rows\": 544,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 157,\n        \"min\": 1,\n        \"max\": 544,\n        \"num_unique_values\": 544,\n        \"samples\": [\n          458,\n          258,\n          358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Information\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 523,\n        \"samples\": [\n          \"Name: Charlotte L., Age: 45, Gender: Female\",\n          \"Bhaskar, 43, Female, 23 days\",\n          \"Name: William R., Age: 45, Gender: Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Symptoms & History\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 443,\n        \"samples\": [\n          \"My acne gets worse when it\\u2019s hot outside. I feel like it\\u2019s constantly breaking out on my face, especially my forehead and chin. I\\u2019ve tried multiple treatments, but nothing seems to work. I don\\u2019t have a history of severe skin conditions, though.\",\n          \"I\\u2019m having trouble seeing things clearly. It feels like there\\u2019s a cloud over my eyes, making everything blurry. I have allergies and a family history of heart disease. Could this be an eye condition?\",\n          \"I get really bad cramps before and during my period. Sometimes, they\\u2019re so painful that I can\\u2019t even get out of bed. Could this be endometriosis?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_w1KqKjbKZx",
        "outputId": "908d26e5-deee-435e-de14-02851cd2a98b"
      },
      "id": "k_w1KqKjbKZx",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "544"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "lx1CcvMNDnjA"
      },
      "id": "lx1CcvMNDnjA"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pP8CKn3qDm5V"
      },
      "id": "pP8CKn3qDm5V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('Healthcareapi')"
      ],
      "metadata": {
        "id": "EXLZWAGEY7Iz"
      },
      "id": "EXLZWAGEY7Iz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = train_df.head(31)"
      ],
      "metadata": {
        "id": "fXuuSoBncTSz"
      },
      "id": "fXuuSoBncTSz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Configure your API key\n",
        "# GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\") # Ensure you have set your API key as an environment variable\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('Gemini 2.0 Flash-Lite')\n",
        "\n",
        "def extract_patient_info(text):\n",
        "    \"\"\"\n",
        "    Extracts patient information from a text transcript using Gemini.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Given the following patient transcript, extract the following information if available.\n",
        "    If not available, return \" \".\n",
        "\n",
        "    Transcript:\n",
        "    {text}\n",
        "\n",
        "    Requested Information:\n",
        "    Primary Symptoms:\n",
        "    Duration of Symptoms:\n",
        "    Severity (Mild, Moderate, Severe):\n",
        "    Past Medical Conditions:\n",
        "    Hospitalizations (reason and year):\n",
        "    Allergies:\n",
        "    Current Medications (name, dosage, frequency):\n",
        "    Smoking (Yes/No, quantity per day):\n",
        "    Alcohol Consumption (Yes/No, frequency):\n",
        "    Exercise Routine (Yes/No, frequency):\n",
        "    Dietary Habits (Vegetarian, Non-Vegetarian, Vegan):\n",
        "    Sleep Pattern (Hours per day, quality of sleep):\n",
        "    Triggering Factors:\n",
        "\n",
        "    Output the information in a JSON-like format, where each requested information is a key and the extracted value is the corresponding value.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        result = response.text\n",
        "\n",
        "        # Basic parsing to create a dictionary. Improved parsing might be needed based on the output format.\n",
        "        info = {}\n",
        "        lines = result.split('\\n')\n",
        "        for line in lines:\n",
        "            if \":\" in line:\n",
        "                key, value = line.split(\":\", 1)\n",
        "                info[key.strip()] = value.strip()\n",
        "        return info\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        return {}\n",
        "\n",
        "def process_dataset(df):\n",
        "    \"\"\"\n",
        "    Processes a DataFrame with patient transcripts and extracts information.\n",
        "    \"\"\"\n",
        "    extracted_data = []\n",
        "    for index, row in df.iterrows():\n",
        "        text = row[\"Symptoms & History\"]\n",
        "        extracted_info = extract_patient_info(text)\n",
        "        extracted_info[\"ID\"] = row[\"ID\"] # Add ID for clarity\n",
        "        extracted_data.append(extracted_info)\n",
        "\n",
        "    return pd.DataFrame(extracted_data)\n",
        "\n",
        "\n",
        "# Process the dataset\n",
        "extracted_df = process_dataset(df)\n",
        "\n",
        "# Print the extracted DataFrame\n",
        "# print(extracted_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rm3Ecs8pVZU2",
        "outputId": "2b6133b9-86b1-4ec0-9720-dfa22c61b154"
      },
      "id": "rm3Ecs8pVZU2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.69ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.19ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.29ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.87ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.32ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.11ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.40ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 154.54ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.71ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.96ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.07ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.59ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.18ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.51ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.01ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.97ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.77ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 162.67ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 158.13ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.49ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.95ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.01ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.59ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 133.86ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.59ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.20ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.92ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.23ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.94ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.95ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.74ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.14ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.00ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.65ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.01ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.23ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.35ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.01ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.22ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.78ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.12ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.77ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.41ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 155.52ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 157.03ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.05ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.23ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.02ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.33ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.49ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.35ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.36ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 130.00ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.82ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.10ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.11ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.63ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.66ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.34ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.05ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.41ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.59ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.17ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.42ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.95ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 177.88ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.85ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.06ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.20ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.41ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.06ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 179.09ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.37ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.21ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 155.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.44ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.12ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.78ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.88ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.18ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.11ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 154.21ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.22ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.34ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.83ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.15ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.27ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.16ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.04ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.87ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.39ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 154.85ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.29ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.39ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 156.77ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.36ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.20ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.38ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.87ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.13ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.42ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.32ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.92ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.29ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.69ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.41ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.89ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.77ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.07ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.84ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.98ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.10ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.43ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 203.68ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.09ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 156.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.05ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.30ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 154.32ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.24ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.23ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.21ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 154.82ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.09ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 155.14ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error processing text: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.43ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-474d5485fe24>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Process the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mextracted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Print the extracted DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-474d5485fe24>\u001b[0m in \u001b[0;36mprocess_dataset\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Symptoms & History\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mextracted_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_patient_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mextracted_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Add ID for clarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mextracted_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-474d5485fe24>\u001b[0m in \u001b[0;36mextract_patient_info\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m             response = GenerativeServiceRestTransport._GenerateContent._get_response(\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(host, metadata, query_params, session, timeout, transcoded_request, body)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             response = getattr(session, method)(\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    538\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('Healthcareapi')\n",
        "\n",
        "# Configure your API key\n",
        "# GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")  # Ensure you have set your API key as an environment variable\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('Gemini 2.0 Flash-Lite')\n",
        "\n",
        "def extract_patient_info(text):\n",
        "    \"\"\"\n",
        "    Extracts patient information from a text transcript using Gemini.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Given the following patient transcript, extract the following information if available.\n",
        "    If not available, return \" \".\n",
        "\n",
        "    Transcript:\n",
        "    {text}\n",
        "\n",
        "    Requested Information:\n",
        "    Primary Symptoms:\n",
        "    Duration of Symptoms:\n",
        "    Severity (Mild, Moderate, Severe):\n",
        "    Past Medical Conditions:\n",
        "    Hospitalizations (reason and year):\n",
        "    Allergies:\n",
        "    Current Medications (name, dosage, frequency):\n",
        "    Smoking (Yes/No, quantity per day):\n",
        "    Alcohol Consumption (Yes/No, frequency):\n",
        "    Exercise Routine (Yes/No, frequency):\n",
        "    Dietary Habits (Vegetarian, Non-Vegetarian, Vegan):\n",
        "    Sleep Pattern (Hours per day, quality of sleep):\n",
        "    Triggering Factors:\n",
        "\n",
        "    Output the information in a JSON-like format, where each requested information is a key and the extracted value is the corresponding value.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        result = response.text\n",
        "\n",
        "        # Basic parsing to create a dictionary. Improved parsing might be needed based on the output format.\n",
        "        info = {}\n",
        "        lines = result.split('\\n')\n",
        "        for line in lines:\n",
        "            if \":\" in line:\n",
        "                key, value = line.split(\":\", 1)\n",
        "                info[key.strip()] = value.strip()\n",
        "        return info\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        return {}\n",
        "\n",
        "def process_dataset(df):\n",
        "    \"\"\"\n",
        "    Processes a DataFrame with patient transcripts and extracts information, respecting a rate limit of 30 requests per minute.\n",
        "    \"\"\"\n",
        "    extracted_data = []\n",
        "    request_count = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        text = row[\"Symptoms & History\"]\n",
        "        extracted_info = extract_patient_info(text)\n",
        "        extracted_info[\"ID\"] = row[\"ID\"]  # Add ID for clarity\n",
        "        extracted_data.append(extracted_info)\n",
        "\n",
        "        request_count += 1\n",
        "\n",
        "        # Enforce rate limit\n",
        "        if request_count >= 30:\n",
        "            elapsed_time = time.time() - start_time\n",
        "            if elapsed_time < 60:\n",
        "                time.sleep(60 - elapsed_time)  # Wait for the remaining time\n",
        "            request_count = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "    return pd.DataFrame(extracted_data)\n",
        "\n",
        "# Process the dataset\n",
        "extracted_df = process_dataset(df)\n"
      ],
      "metadata": {
        "id": "m50FgNsglIBo",
        "outputId": "e031060b-5340-4f5e-b3f8-4a2c84950d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true
      },
      "id": "m50FgNsglIBo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 535.71ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.84ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.29ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 154.39ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.99ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.99ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.31ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 154.14ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.10ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 330.12ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.02ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.78ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.90ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.79ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.80ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.05ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.21ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.99ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 355.41ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.73ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.55ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.94ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.76ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.73ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 254.17ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.17ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.88ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 279.30ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.83ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.34ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.49ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.65ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.24ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.89ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.01ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.17ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.06ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.96ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.36ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.92ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.97ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.64ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.80ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.24ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.82ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.98ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.48ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.84ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.81ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.97ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.93ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.38ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.99ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.19ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.01ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.32ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.96ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.30ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.85ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 254.44ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 203.55ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.18ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 154.63ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.63ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.94ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 279.74ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 228.92ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 228.37ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.21ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.84ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 182.54ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.00ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.99ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.08ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 177.97ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.96ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.33ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.79ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.42ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 203.40ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.05ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.67ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 253.88ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 152.88ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.09ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 304.81ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.29ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.80ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 178.32ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n",
            "Error processing text: 400 POST https://generativelanguage.googleapis.com/v1beta/models/Gemini%202.0%20Flash-Lite:generateContent?%24alt=json%3Benum-encoding%3Dint: * GenerateContentRequest.model: unexpected model name format\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-211f9777aff2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Process the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mextracted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# Print the extracted DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-211f9777aff2>\u001b[0m in \u001b[0;36mprocess_dataset\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait for the remaining time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mrequest_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_df"
      ],
      "metadata": {
        "id": "0UDcOhH9Zdb3"
      },
      "id": "0UDcOhH9Zdb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using gemini api"
      ],
      "metadata": {
        "id": "FeAJfrdwsD4M"
      },
      "id": "FeAJfrdwsD4M"
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata  # Assuming you are in Colab\n",
        "\n",
        "# --- API Keys ---\n",
        "API_KEYS = [\n",
        "    userdata.get('Healthcareapi'),\n",
        "    userdata.get('Sachin'),\n",
        "    userdata.get('Lakshmi'),\n",
        "    userdata.get('Akash'),\n",
        "]\n",
        "NUM_API_KEYS = len(API_KEYS)\n",
        "current_api_key_index = 0\n",
        "\n",
        "# --- Rate Limits ---\n",
        "RPM_LIMIT = 30\n",
        "RPD_LIMIT = 1500\n",
        "MIN_SLEEP_SECONDS = 2  # Buffer to avoid hitting RPM limit exactly\n",
        "\n",
        "# --- File to store processed data ---\n",
        "OUTPUT_CSV_FILE = \"extracted_data_progress.csv\"\n",
        "\n",
        "# --- Model Name ---\n",
        "MODEL_NAME = \"gemini-2.0-flash-lite\"\n",
        "\n",
        "# --- Initialize Client (will be configured with the current API key) ---\n",
        "client = None\n",
        "\n",
        "def configure_api(api_key):\n",
        "    \"\"\"Configures the Gemini API client with the given key.\"\"\"\n",
        "    global client\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    print(f\"Using API Key {API_KEYS.index(api_key) + 1}\")\n",
        "\n",
        "def switch_api_key():\n",
        "    \"\"\"Switches to the next available API key.\"\"\"\n",
        "    global current_api_key_index\n",
        "    current_api_key_index = (current_api_key_index + 1) % NUM_API_KEYS\n",
        "    configure_api(API_KEYS[current_api_key_index])\n",
        "\n",
        "def extract_patient_info(text):\n",
        "    \"\"\"\n",
        "    Extracts patient information from a text transcript using Gemini.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Given the following patient transcript, extract the following information if available.\n",
        "    If not available, return \" \".\n",
        "\n",
        "    Transcript:\n",
        "    {text}\n",
        "\n",
        "    Requested Information:\n",
        "    Primary Symptoms:\n",
        "    Duration of Symptoms:\n",
        "    Severity (Mild, Moderate, Severe):\n",
        "    Past Medical Conditions:\n",
        "    Hospitalizations (reason and year):\n",
        "    Allergies:\n",
        "    Current Medications (name, dosage, frequency):\n",
        "    Smoking (Yes/No, quantity per day):\n",
        "    Alcohol Consumption (Yes/No, frequency):\n",
        "    Exercise Routine (Yes/No, frequency):\n",
        "    Dietary Habits (Vegetarian, Non-Vegetarian, Vegan):\n",
        "    Sleep Pattern (Hours per day, quality of sleep):\n",
        "    Triggering Factors:\n",
        "\n",
        "    Output the information in a JSON-like format, where each requested information is a key and the extracted value is the corresponding value.\n",
        "    \"\"\"\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[types.Part.from_text(text=prompt)],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"text/plain\",\n",
        "    )\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=MODEL_NAME,\n",
        "            contents=contents,\n",
        "            config=generate_content_config,\n",
        "        )\n",
        "        result = response.text\n",
        "\n",
        "        info = {}\n",
        "        lines = result.split('\\n')\n",
        "        for line in lines:\n",
        "            if \":\" in line:\n",
        "                key, value = line.split(\":\", 1)\n",
        "                info[key.strip()] = value.strip()\n",
        "        return info\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_dataset_with_resume(df):\n",
        "    \"\"\"\n",
        "    Processes a DataFrame with patient transcripts, extracts information,\n",
        "    manages multiple API keys, respects rate limits, and supports resuming.\n",
        "    Forces API key switch upon hitting RPM limit.\n",
        "    \"\"\"\n",
        "    start_row_index = 0\n",
        "    processed_data = []\n",
        "\n",
        "    # Load any previously processed data\n",
        "    if os.path.exists(OUTPUT_CSV_FILE):\n",
        "        try:\n",
        "            processed_df = pd.read_csv(OUTPUT_CSV_FILE)\n",
        "            processed_data = processed_df.to_dict('records')\n",
        "            start_row_index = len(processed_df)\n",
        "            print(f\"Resuming processing from row {start_row_index}.\")\n",
        "        except pd.errors.EmptyDataError:\n",
        "            print(\"Previous progress file is empty.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading previous progress: {e}\")\n",
        "\n",
        "    num_rows = len(df)\n",
        "    if start_row_index >= num_rows:\n",
        "        print(\"All rows have been processed previously.\")\n",
        "        return pd.DataFrame(processed_data)\n",
        "\n",
        "    remaining_df = df.iloc[start_row_index:]\n",
        "    api_call_counts = [0] * NUM_API_KEYS\n",
        "    last_reset_times = [time.time()] * NUM_API_KEYS\n",
        "\n",
        "    configure_api(API_KEYS[current_api_key_index])\n",
        "\n",
        "    for index, row in remaining_df.iterrows():\n",
        "        api_key_index = current_api_key_index\n",
        "\n",
        "        if api_call_counts[api_key_index] >= RPD_LIMIT:\n",
        "            print(f\"Daily limit reached for API Key {api_key_index + 1}. Switching key...\")\n",
        "            switch_api_key()\n",
        "            api_key_index = current_api_key_index\n",
        "            if all(count >= RPD_LIMIT for count in api_call_counts):\n",
        "                print(\"Daily limit reached for all API keys. Please run again tomorrow.\")\n",
        "                break  # Stop processing for the day\n",
        "\n",
        "        start_time = time.time()\n",
        "        extracted_info = extract_patient_info(row[\"Symptoms & History\"])\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "\n",
        "        if extracted_info is not None:  # Only save if extraction was successful\n",
        "            extracted_info[\"ID\"] = row[\"ID\"]\n",
        "            processed_data.append(extracted_info)\n",
        "            # Save progress after each successful extraction\n",
        "            pd.DataFrame(processed_data).to_csv(OUTPUT_CSV_FILE, index=False)\n",
        "            api_call_counts[api_key_index] += 1\n",
        "\n",
        "        # Enforce rate limit (RPM)\n",
        "        elapsed_time = time.time() - last_reset_times[api_key_index]\n",
        "        requests_this_minute = sum(1 for item in processed_data if hasattr(item, '__contains__') and 'ID' in item and item['ID'] >= start_row_index and time.time() - start_time <= 60) # More accurate RPM tracking\n",
        "        if requests_this_minute >= RPM_LIMIT:\n",
        "            sleep_duration = 60 - elapsed_time + MIN_SLEEP_SECONDS\n",
        "            print(f\"Rate limit (RPM) reached for API Key {api_key_index + 1}. Sleeping for {sleep_duration:.2f} seconds...\")\n",
        "            time.sleep(sleep_duration)\n",
        "            switch_api_key()  # Force switch API key after sleeping due to RPM limit\n",
        "            last_reset_times[current_api_key_index] = time.time() # Reset timer for the new key\n",
        "\n",
        "        elif requests_this_minute >= RPM_LIMIT - 5:\n",
        "            print(\"Nearing RPM limit, switching API key...\")\n",
        "            switch_api_key()\n",
        "\n",
        "        elif len(processed_data) % (RPM_LIMIT * 5) == 0 and len(processed_data) > 0:\n",
        "            print(\"Periodic API key switch...\")\n",
        "            switch_api_key()\n",
        "\n",
        "    return pd.DataFrame(processed_data)\n",
        "\n",
        "# --- Process the dataset ---\n",
        "print(f\"Total number of records in the dataset: {len(original)}\")\n",
        "if not original.empty:\n",
        "    extracted_df = process_dataset_with_resume(original)\n",
        "    print(\"\\nProcessing complete or stopped. Extracted data (up to the point of completion/interruption) is in:\")\n",
        "    print(OUTPUT_CSV_FILE)\n",
        "else:\n",
        "    print(\"The 'original' DataFrame is empty.\")"
      ],
      "metadata": {
        "id": "w3lXB2jtlmHC",
        "outputId": "2c51e203-cb52-474a-e859-0c6babdeff92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "id": "w3lXB2jtlmHC",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of records in the dataset: 544\n",
            "Resuming processing from row 87.\n",
            "Using API Key 1\n",
            "Nearing RPM limit, switching API key...\n",
            "Using API Key 2\n",
            "Nearing RPM limit, switching API key...\n",
            "Using API Key 3\n",
            "Nearing RPM limit, switching API key...\n",
            "Using API Key 4\n",
            "Nearing RPM limit, switching API key...\n",
            "Using API Key 1\n",
            "Nearing RPM limit, switching API key...\n",
            "Using API Key 2\n",
            "Rate limit (RPM) reached for API Key 2. Sleeping for 27.22 seconds...\n",
            "Using API Key 3\n",
            "Rate limit (RPM) reached for API Key 3. Sleeping for 60.74 seconds...\n",
            "Using API Key 4\n",
            "Rate limit (RPM) reached for API Key 4. Sleeping for 60.70 seconds...\n",
            "Using API Key 1\n",
            "Rate limit (RPM) reached for API Key 1. Sleeping for 60.73 seconds...\n",
            "Using API Key 2\n",
            "Rate limit (RPM) reached for API Key 2. Sleeping for 60.75 seconds...\n",
            "Using API Key 3\n",
            "Rate limit (RPM) reached for API Key 3. Sleeping for 60.64 seconds...\n",
            "Using API Key 4\n",
            "Rate limit (RPM) reached for API Key 4. Sleeping for 60.72 seconds...\n",
            "Using API Key 1\n",
            "Rate limit (RPM) reached for API Key 1. Sleeping for 60.69 seconds...\n",
            "Using API Key 2\n",
            "Rate limit (RPM) reached for API Key 2. Sleeping for 60.72 seconds...\n",
            "Using API Key 3\n",
            "Rate limit (RPM) reached for API Key 3. Sleeping for 60.69 seconds...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-63735d11fec5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total number of records in the dataset: {len(original)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mextracted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_dataset_with_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nProcessing complete or stopped. Extracted data (up to the point of completion/interruption) is in:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_CSV_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-63735d11fec5>\u001b[0m in \u001b[0;36mprocess_dataset_with_resume\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0msleep_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMIN_SLEEP_SECONDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Rate limit (RPM) reached for API Key {api_key_index + 1}. Sleeping for {sleep_duration:.2f} seconds...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mswitch_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Force switch API key after sleeping due to RPM limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mlast_reset_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_api_key_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Reset timer for the new key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata  # Assuming you are in Colab\n",
        "\n",
        "# --- API Keys ---\n",
        "API_KEYS = [\n",
        "    userdata.get('Healthcareapi'),\n",
        "    userdata.get('Sachin'),\n",
        "    userdata.get('Lakshmi'),\n",
        "    userdata.get('Akash'),\n",
        "]\n",
        "NUM_API_KEYS = len(API_KEYS)\n",
        "current_api_key_index = 0\n",
        "api_key_cycle_count = 0  # Track cycles through all API keys\n",
        "\n",
        "# --- Rate Limits ---\n",
        "MAX_RETRIES = 3  # Number of times to retry a failed request\n",
        "WAIT_ON_ERROR_SECONDS = 60\n",
        "DAILY_LIMIT_REACHED = False\n",
        "\n",
        "# --- File to store processed data ---\n",
        "OUTPUT_CSV_FILE = \"extracted_data_progress.csv\"\n",
        "\n",
        "# --- Model Name ---\n",
        "MODEL_NAME = \"gemini-2.0-flash-lite\"\n",
        "\n",
        "# --- Initialize Client (will be configured with the current API key) ---\n",
        "client = None\n",
        "\n",
        "def configure_api(api_key):\n",
        "    \"\"\"Configures the Gemini API client with the given key.\"\"\"\n",
        "    global client\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    print(f\"Using API Key {API_KEYS.index(api_key) + 1}\")\n",
        "\n",
        "def switch_api_key():\n",
        "    \"\"\"Switches to the next available API key.\"\"\"\n",
        "    global current_api_key_index, api_key_cycle_count\n",
        "    current_api_key_index = (current_api_key_index + 1) % NUM_API_KEYS\n",
        "    configure_api(API_KEYS[current_api_key_index])\n",
        "    if current_api_key_index == 0:\n",
        "        api_key_cycle_count += 1\n",
        "\n",
        "def extract_patient_info(text):\n",
        "    \"\"\"\n",
        "    Extracts patient information from a text transcript using Gemini.\n",
        "    Switches API key on any exception other than a successful response.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Given the following patient transcript, extract the following information if available.\n",
        "    If not available, return \" \".\n",
        "\n",
        "    Transcript:\n",
        "    {text}\n",
        "\n",
        "    Requested Information:\n",
        "    Primary Symptoms:\n",
        "    Duration of Symptoms:\n",
        "    Severity (Mild, Moderate, Severe):\n",
        "    Past Medical Conditions:\n",
        "    Hospitalizations (reason and year):\n",
        "    Allergies:\n",
        "    Current Medications (name, dosage, frequency):\n",
        "    Smoking (Yes/No, quantity per day):\n",
        "    Alcohol Consumption (Yes/No, frequency):\n",
        "    Exercise Routine (Yes/No, frequency):\n",
        "    Dietary Habits (Vegetarian, Non-Vegetarian, Vegan):\n",
        "    Sleep Pattern (Hours per day, quality of sleep):\n",
        "    Triggering Factors:\n",
        "\n",
        "    Output the information in a JSON-like format, where each requested information is a key and the extracted value is the corresponding value.\n",
        "    \"\"\"\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[types.Part.from_text(text=prompt)],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"text/plain\",\n",
        "    )\n",
        "\n",
        "    retries = 0\n",
        "    while retries < MAX_RETRIES and not DAILY_LIMIT_REACHED:\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=MODEL_NAME,\n",
        "                contents=contents,\n",
        "                config=generate_content_config,\n",
        "            )\n",
        "            result = response.text\n",
        "            info = {}\n",
        "            lines = result.split('\\n')\n",
        "            for line in lines:\n",
        "                if \":\" in line:\n",
        "                    key, value = line.split(\":\", 1)\n",
        "                    info[key.strip()] = value.strip()\n",
        "            return info\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}. Switching API key...\")\n",
        "            switch_api_key()\n",
        "            retries += 1\n",
        "            if retries == MAX_RETRIES:\n",
        "                print(\"Max retries reached for this request.\")\n",
        "            time.sleep(WAIT_ON_ERROR_SECONDS)  # Wait after switching key on error\n",
        "\n",
        "    return None\n",
        "\n",
        "def process_dataset_with_resume(df):\n",
        "    \"\"\"\n",
        "    Processes a DataFrame with patient transcripts, extracts information,\n",
        "    manages multiple API keys, and supports resuming with error handling.\n",
        "    \"\"\"\n",
        "    global DAILY_LIMIT_REACHED, api_key_cycle_count\n",
        "    start_row_index = 0\n",
        "    processed_data = []\n",
        "\n",
        "    # Load any previously processed data\n",
        "    if os.path.exists(OUTPUT_CSV_FILE):\n",
        "        try:\n",
        "            processed_df = pd.read_csv(OUTPUT_CSV_FILE)\n",
        "            processed_data = processed_df.to_dict('records')\n",
        "            start_row_index = len(processed_df)\n",
        "            print(f\"Resuming processing from row {start_row_index}.\")\n",
        "        except pd.errors.EmptyDataError:\n",
        "            print(\"Previous progress file is empty.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading previous progress: {e}\")\n",
        "\n",
        "    num_rows = len(df)\n",
        "    if start_row_index >= num_rows:\n",
        "        print(\"All rows have been processed previously.\")\n",
        "        return pd.DataFrame(processed_data)\n",
        "\n",
        "    remaining_df = df.iloc[start_row_index:]\n",
        "    configure_api(API_KEYS[current_api_key_index])\n",
        "\n",
        "    for index, row in remaining_df.iterrows():\n",
        "        if DAILY_LIMIT_REACHED:\n",
        "            print(\"Daily limit reached. Stopping processing.\")\n",
        "            break\n",
        "\n",
        "        extracted_info = extract_patient_info(row[\"Symptoms & History\"])\n",
        "\n",
        "        if extracted_info is not None:\n",
        "            extracted_info[\"ID\"] = row[\"ID\"]\n",
        "            processed_data.append(extracted_info)\n",
        "            pd.DataFrame(processed_data).to_csv(OUTPUT_CSV_FILE, index=False)\n",
        "        else:\n",
        "            print(f\"Failed to extract information for ID: {row['ID']}\")\n",
        "\n",
        "        if api_key_cycle_count > 0 and current_api_key_index == 0:\n",
        "            print(f\"End of API key list reached for the {api_key_cycle_count} time. Waiting for {WAIT_ON_ERROR_SECONDS} seconds...\")\n",
        "            time.sleep(WAIT_ON_ERROR_SECONDS)\n",
        "            api_key_cycle_count = 0 # Reset cycle count after waiting\n",
        "\n",
        "    return pd.DataFrame(processed_data)\n",
        "\n",
        "# --- Process the dataset ---\n",
        "print(f\"Total number of records in the dataset: {len(original)}\")\n",
        "if not original.empty:\n",
        "    extracted_df = process_dataset_with_resume(original)\n",
        "    print(\"\\nProcessing complete or stopped. Extracted data (up to the point of completion/interruption) is in:\")\n",
        "    print(OUTPUT_CSV_FILE)\n",
        "else:\n",
        "    print(\"The 'original' DataFrame is empty.\")"
      ],
      "metadata": {
        "id": "S1CYExIRRPGh",
        "outputId": "234f98f7-abee-439c-c702-27a98b89b671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S1CYExIRRPGh",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of records in the dataset: 544\n",
            "Resuming processing from row 232.\n",
            "Using API Key 1\n",
            "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}, 'quotaValue': '30'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}. Switching API key...\n",
            "Using API Key 2\n",
            "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}, 'quotaValue': '30'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '56s'}]}}. Switching API key...\n",
            "Using API Key 3\n",
            "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}, 'quotaValue': '30'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}. Switching API key...\n",
            "Using API Key 4\n",
            "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}, 'quotaValue': '30'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}. Switching API key...\n",
            "Using API Key 1\n",
            "End of API key list reached for the 1 time. Waiting for 60 seconds...\n",
            "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}, 'quotaValue': '30'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}. Switching API key...\n",
            "Using API Key 2\n",
            "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}, 'quotaValue': '30'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}. Switching API key...\n",
            "Using API Key 3\n",
            "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}, 'quotaValue': '30'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}. Switching API key...\n",
            "Using API Key 4\n",
            "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}, 'quotaValue': '30'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}. Switching API key...\n",
            "Using API Key 1\n",
            "End of API key list reached for the 1 time. Waiting for 60 seconds...\n",
            "\n",
            "Processing complete or stopped. Extracted data (up to the point of completion/interruption) is in:\n",
            "extracted_data_progress.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}